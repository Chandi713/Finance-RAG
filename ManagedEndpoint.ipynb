{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Before, starting the deployment make sure AzureMl kernal is selected"
      ],
      "metadata": {
        "id": "TzFc4xMVPhNd"
      },
      "id": "TzFc4xMVPhNd"
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for package\n",
        "!pip show azure-ai-ml"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Name: azure-ai-ml\r\nVersion: 1.28.1\r\nSummary: Microsoft Azure Machine Learning Client Library for Python\r\nHome-page: https://github.com/Azure/azure-sdk-for-python\r\nAuthor: Microsoft Corporation\r\nAuthor-email: azuresdkengsysadmins@microsoft.com\r\nLicense: MIT License\r\nLocation: /anaconda/envs/azureml_py38/lib/python3.10/site-packages\r\nRequires: azure-common, azure-core, azure-mgmt-core, azure-monitor-opentelemetry, azure-storage-blob, azure-storage-file-datalake, azure-storage-file-share, colorama, isodate, jsonschema, marshmallow, msrest, pydash, pyjwt, pyyaml, six, strictyaml, tqdm, typing-extensions\r\nRequired-by: \r\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "id": "lZLdjfVNO8pD",
        "gather": {
          "logged": 1753029331127
        }
      },
      "id": "lZLdjfVNO8pD"
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the package if not available\n",
        "!pip install azure-ai-ml"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting azure-ai-ml\n  Downloading azure_ai_ml-1.28.1-py3-none-any.whl (13.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m112.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: colorama<1.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (0.4.6)\nCollecting azure-monitor-opentelemetry\n  Downloading azure_monitor_opentelemetry-1.6.11-py3-none-any.whl (25 kB)\nCollecting pydash<9.0.0,>=6.0.0\n  Downloading pydash-8.0.5-py3-none-any.whl (102 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.1/102.1 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting azure-storage-file-datalake>=12.2.0\n  Downloading azure_storage_file_datalake-12.21.0-py3-none-any.whl (264 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.1/264.1 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: isodate<1.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (0.7.2)\nRequirement already satisfied: pyjwt<3.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (2.4.0)\nRequirement already satisfied: azure-mgmt-core>=1.3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (1.5.0)\nCollecting azure-storage-file-share\n  Downloading azure_storage_file_share-12.22.0-py3-none-any.whl (291 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.3/291.3 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting marshmallow<4.0.0,>=3.5\n  Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: msrest<1.0.0,>=0.6.18 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (0.7.1)\nRequirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (4.23.0)\nRequirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (1.17.0)\nRequirement already satisfied: azure-core>=1.23.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (1.33.0)\nCollecting strictyaml<2.0.0\n  Downloading strictyaml-1.7.3-py3-none-any.whl (123 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.9/123.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: azure-storage-blob>=12.10.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (12.25.1)\nRequirement already satisfied: typing-extensions<5.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (4.13.2)\nRequirement already satisfied: azure-common>=1.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (1.1.28)\nRequirement already satisfied: pyyaml<7.0.0,>=5.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (6.0.2)\nRequirement already satisfied: tqdm<5.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (4.67.1)\nRequirement already satisfied: requests>=2.21.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-core>=1.23.0->azure-ai-ml) (2.32.3)\nRequirement already satisfied: cryptography>=2.1.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-storage-blob>=12.10.0->azure-ai-ml) (38.0.4)\nCollecting azure-storage-blob>=12.10.0\n  Downloading azure_storage_blob-12.26.0-py3-none-any.whl (412 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.9/412.9 kB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: rpds-py>=0.7.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (0.19.1)\nRequirement already satisfied: referencing>=0.28.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (0.36.2)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (2024.10.1)\nRequirement already satisfied: attrs>=22.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (25.3.0)\nRequirement already satisfied: packaging>=17.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.5->azure-ai-ml) (25.0)\nRequirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msrest<1.0.0,>=0.6.18->azure-ai-ml) (2.0.0)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msrest<1.0.0,>=0.6.18->azure-ai-ml) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from strictyaml<2.0.0->azure-ai-ml) (2.9.0.post0)\nCollecting opentelemetry-resource-detector-azure~=0.1.4\n  Downloading opentelemetry_resource_detector_azure-0.1.5-py3-none-any.whl (14 kB)\nCollecting azure-monitor-opentelemetry-exporter~=1.0.0b40\n  Downloading azure_monitor_opentelemetry_exporter-1.0.0b40-py2.py3-none-any.whl (159 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.0/160.0 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting opentelemetry-instrumentation-urllib<0.53b0,>=0.49b0\n  Downloading opentelemetry_instrumentation_urllib-0.52b1-py3-none-any.whl (12 kB)\nCollecting opentelemetry-instrumentation-flask<0.53b0,>=0.49b0\n  Downloading opentelemetry_instrumentation_flask-0.52b1-py3-none-any.whl (14 kB)\nCollecting opentelemetry-instrumentation-fastapi<0.53b0,>=0.49b0\n  Downloading opentelemetry_instrumentation_fastapi-0.52b1-py3-none-any.whl (12 kB)\nCollecting opentelemetry-instrumentation-requests<0.53b0,>=0.49b0\n  Downloading opentelemetry_instrumentation_requests-0.52b1-py3-none-any.whl (12 kB)\nCollecting opentelemetry-instrumentation-django<0.53b0,>=0.49b0\n  Downloading opentelemetry_instrumentation_django-0.52b1-py3-none-any.whl (19 kB)\nCollecting opentelemetry-instrumentation-psycopg2<0.53b0,>=0.49b0\n  Downloading opentelemetry_instrumentation_psycopg2-0.52b1-py3-none-any.whl (10 kB)\nCollecting azure-core-tracing-opentelemetry~=1.0.0b11\n  Downloading azure_core_tracing_opentelemetry-1.0.0b12-py3-none-any.whl (11 kB)\nCollecting opentelemetry-sdk<1.32,>=1.28.0\n  Downloading opentelemetry_sdk-1.31.1-py3-none-any.whl (118 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting opentelemetry-instrumentation-urllib3<0.53b0,>=0.49b0\n  Downloading opentelemetry_instrumentation_urllib3-0.52b1-py3-none-any.whl (13 kB)\nRequirement already satisfied: opentelemetry-api>=1.12.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-core-tracing-opentelemetry~=1.0.0b11->azure-monitor-opentelemetry->azure-ai-ml) (1.32.0)\nCollecting psutil<8,>=5.9\n  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting fixedint==0.1.6\n  Downloading fixedint-0.1.6-py3-none-any.whl (12 kB)\nRequirement already satisfied: azure-identity~=1.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry-exporter~=1.0.0b40->azure-monitor-opentelemetry->azure-ai-ml) (1.21.0)\nRequirement already satisfied: cffi>=1.12 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from cryptography>=2.1.4->azure-storage-blob>=12.10.0->azure-ai-ml) (1.17.1)\nCollecting opentelemetry-semantic-conventions==0.52b1\n  Downloading opentelemetry_semantic_conventions-0.52b1-py3-none-any.whl (183 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting opentelemetry-instrumentation-wsgi==0.52b1\n  Downloading opentelemetry_instrumentation_wsgi-0.52b1-py3-none-any.whl (14 kB)\nCollecting opentelemetry-instrumentation==0.52b1\n  Downloading opentelemetry_instrumentation-0.52b1-py3-none-any.whl (31 kB)\nCollecting opentelemetry-util-http==0.52b1\n  Downloading opentelemetry_util_http-0.52b1-py3-none-any.whl (7.3 kB)\nRequirement already satisfied: wrapt<2.0.0,>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.52b1->opentelemetry-instrumentation-django<0.53b0,>=0.49b0->azure-monitor-opentelemetry->azure-ai-ml) (1.14.1)\nRequirement already satisfied: deprecated>=1.2.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-semantic-conventions==0.52b1->opentelemetry-instrumentation-django<0.53b0,>=0.49b0->azure-monitor-opentelemetry->azure-ai-ml) (1.2.18)\nCollecting opentelemetry-api>=1.12.0\n  Downloading opentelemetry_api-1.31.1-py3-none-any.whl (65 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.2/65.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-api>=1.12.0->azure-core-tracing-opentelemetry~=1.0.0b11->azure-monitor-opentelemetry->azure-ai-ml) (8.2.0)\nCollecting opentelemetry-instrumentation-asgi==0.52b1\n  Downloading opentelemetry_instrumentation_asgi-0.52b1-py3-none-any.whl (16 kB)\nCollecting asgiref~=3.0\n  Downloading asgiref-3.9.1-py3-none-any.whl (23 kB)\nCollecting opentelemetry-instrumentation-dbapi==0.52b1\n  Downloading opentelemetry_instrumentation_dbapi-0.52b1-py3-none-any.whl (12 kB)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (1.26.20)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (3.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (3.4.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests-oauthlib>=0.5.0->msrest<1.0.0,>=0.6.18->azure-ai-ml) (3.2.2)\nRequirement already satisfied: msal-extensions>=1.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-identity~=1.17->azure-monitor-opentelemetry-exporter~=1.0.0b40->azure-monitor-opentelemetry->azure-ai-ml) (1.2.0)\nRequirement already satisfied: msal>=1.30.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-identity~=1.17->azure-monitor-opentelemetry-exporter~=1.0.0b40->azure-monitor-opentelemetry->azure-ai-ml) (1.31.2b1)\nRequirement already satisfied: pycparser in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12.10.0->azure-ai-ml) (2.22)\nRequirement already satisfied: zipp>=0.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.12.0->azure-core-tracing-opentelemetry~=1.0.0b11->azure-monitor-opentelemetry->azure-ai-ml) (3.19.2)\nRequirement already satisfied: portalocker<3,>=1.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msal-extensions>=1.2.0->azure-identity~=1.17->azure-monitor-opentelemetry-exporter~=1.0.0b40->azure-monitor-opentelemetry->azure-ai-ml) (2.10.1)\nInstalling collected packages: fixedint, pydash, psutil, opentelemetry-util-http, marshmallow, asgiref, strictyaml, opentelemetry-api, opentelemetry-semantic-conventions, azure-storage-file-share, azure-storage-blob, azure-core-tracing-opentelemetry, opentelemetry-sdk, opentelemetry-instrumentation, azure-storage-file-datalake, opentelemetry-resource-detector-azure, opentelemetry-instrumentation-wsgi, opentelemetry-instrumentation-urllib3, opentelemetry-instrumentation-urllib, opentelemetry-instrumentation-requests, opentelemetry-instrumentation-dbapi, opentelemetry-instrumentation-asgi, opentelemetry-instrumentation-psycopg2, opentelemetry-instrumentation-flask, opentelemetry-instrumentation-fastapi, opentelemetry-instrumentation-django, azure-monitor-opentelemetry-exporter, azure-monitor-opentelemetry, azure-ai-ml\n  Attempting uninstall: psutil\n    Found existing installation: psutil 5.2.2\n    Uninstalling psutil-5.2.2:\n      Successfully uninstalled psutil-5.2.2\n  Attempting uninstall: opentelemetry-api\n    Found existing installation: opentelemetry-api 1.32.0\n    Uninstalling opentelemetry-api-1.32.0:\n      Successfully uninstalled opentelemetry-api-1.32.0\n  Attempting uninstall: opentelemetry-semantic-conventions\n    Found existing installation: opentelemetry-semantic-conventions 0.53b0\n    Uninstalling opentelemetry-semantic-conventions-0.53b0:\n      Successfully uninstalled opentelemetry-semantic-conventions-0.53b0\n  Attempting uninstall: azure-storage-blob\n    Found existing installation: azure-storage-blob 12.25.1\n    Uninstalling azure-storage-blob-12.25.1:\n      Successfully uninstalled azure-storage-blob-12.25.1\n  Attempting uninstall: opentelemetry-sdk\n    Found existing installation: opentelemetry-sdk 1.32.0\n    Uninstalling opentelemetry-sdk-1.32.0:\n      Successfully uninstalled opentelemetry-sdk-1.32.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nmlflow-skinny 2.21.3 requires packaging<25, but you have packaging 25.0 which is incompatible.\njupyterlab-nvdashboard 0.13.0 requires jupyterlab>=4, but you have jupyterlab 3.6.8 which is incompatible.\njupyter-resource-usage 0.7.2 requires psutil~=5.6, but you have psutil 7.0.0 which is incompatible.\ndask-sql 2024.5.0 requires dask[dataframe]>=2024.4.1, but you have dask 2023.2.0 which is incompatible.\ndask-sql 2024.5.0 requires distributed>=2024.4.1, but you have distributed 2023.2.0 which is incompatible.\nazureml-training-tabular 1.60.0 requires psutil<5.9.4,>=5.2.2, but you have psutil 7.0.0 which is incompatible.\nazureml-training-tabular 1.60.0 requires scipy<1.11.0,>=1.0.0, but you have scipy 1.11.0 which is incompatible.\nazureml-mlflow 1.60.0 requires azure-storage-blob<=12.19.0,>=12.5.0, but you have azure-storage-blob 12.26.0 which is incompatible.\nazureml-automl-runtime 1.60.0 requires psutil<5.9.4,>=5.2.2, but you have psutil 7.0.0 which is incompatible.\nazureml-automl-dnn-nlp 1.60.0 requires torch==2.2.2, but you have torch 2.6.0 which is incompatible.\nadlfs 2024.12.0 requires fsspec>=2023.12.0, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed asgiref-3.9.1 azure-ai-ml-1.28.1 azure-core-tracing-opentelemetry-1.0.0b12 azure-monitor-opentelemetry-1.6.11 azure-monitor-opentelemetry-exporter-1.0.0b40 azure-storage-blob-12.26.0 azure-storage-file-datalake-12.21.0 azure-storage-file-share-12.22.0 fixedint-0.1.6 marshmallow-3.26.1 opentelemetry-api-1.31.1 opentelemetry-instrumentation-0.52b1 opentelemetry-instrumentation-asgi-0.52b1 opentelemetry-instrumentation-dbapi-0.52b1 opentelemetry-instrumentation-django-0.52b1 opentelemetry-instrumentation-fastapi-0.52b1 opentelemetry-instrumentation-flask-0.52b1 opentelemetry-instrumentation-psycopg2-0.52b1 opentelemetry-instrumentation-requests-0.52b1 opentelemetry-instrumentation-urllib-0.52b1 opentelemetry-instrumentation-urllib3-0.52b1 opentelemetry-instrumentation-wsgi-0.52b1 opentelemetry-resource-detector-azure-0.1.5 opentelemetry-sdk-1.31.1 opentelemetry-semantic-conventions-0.52b1 opentelemetry-util-http-0.52b1 psutil-7.0.0 pydash-8.0.5 strictyaml-1.7.3\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "id": "RKxwgpz2PVen",
        "gather": {
          "logged": 1753026230899
        }
      },
      "id": "RKxwgpz2PVen"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# User Identity verification"
      ],
      "metadata": {
        "id": "_OfL3cogPCW6"
      },
      "id": "_OfL3cogPCW6"
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "# Get the registered model\n",
        "from azure.ai.ml.entities import (\n",
        "    ManagedOnlineEndpoint,\n",
        "    ManagedOnlineDeployment,\n",
        "    Environment,\n",
        "    CodeConfiguration,\n",
        "    Model,\n",
        "    OnlineRequestSettings\n",
        ")\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1753026233409
        },
        "id": "e4ce172a-7209-4f33-94d2-0c43b648a520"
      },
      "id": "e4ce172a-7209-4f33-94d2-0c43b648a520"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize ML Client"
      ],
      "metadata": {
        "id": "2WDAnb1sPOmr"
      },
      "id": "2WDAnb1sPOmr"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get a handle to workspace\n",
        "ml_client = MLClient.from_config(credential=credential)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /config.json\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1753026234075
        },
        "id": "ecc92cbd-8193-4371-a952-c74ddc52fdd6",
        "outputId": "32bdea53-c586-4cde-e974-401c25e6fa50"
      },
      "id": "ecc92cbd-8193-4371-a952-c74ddc52fdd6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize an endpoint"
      ],
      "metadata": {
        "id": "monkk5m0QBFC"
      },
      "id": "monkk5m0QBFC"
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint_name = \"gte-finance-endpoint\"\n",
        "# Create an online endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=endpoint_name,\n",
        "    description=\"Endpoint for GTE Finance model\",\n",
        "    auth_mode=\"key\"\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1753029353890
        },
        "id": "ffa5244d-223a-41a1-a17e-04913cc87d9b"
      },
      "id": "ffa5244d-223a-41a1-a17e-04913cc87d9b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Register the embedding model with ML Workspace"
      ],
      "metadata": {
        "id": "2581sbXRQHwh"
      },
      "id": "2581sbXRQHwh"
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(\n",
        "       name=\"gte-finance-model\",\n",
        "       version=\"1\",\n",
        "       description=\"FinanceRAG embedding model\",\n",
        "       path=\"./model/gte-finance-model/\",\n",
        "       type=\"custom_model\"\n",
        "   )\n",
        "ml_client.models.create_or_update(model)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\u001b[32mUploading gte-finance-model (28.92 MBs): 100%|██████████| 28920962/28920962 [00:00<00:00, 53327542.02it/s]\n\u001b[39m\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "Model({'job_name': None, 'intellectual_property': None, 'system_metadata': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'gte-finance-model', 'description': 'FinanceRAG embedding model', 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/4be8a069-9dad-4913-a634-fc7605684d95/resourceGroups/financerag-rgf846e66535fa4a64bd/providers/Microsoft.MachineLearningServices/workspaces/financerag-mlwf846e66535fa4a64bd/models/gte-finance-model/versions/1', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/cif846e66535fa4a64bd/code/Users/capcool79/checkout', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x76a8700f79a0>, 'serialize': <msrest.serialization.Serializer object at 0x76a8700f5a80>, 'version': '1', 'latest_version': None, 'path': 'azureml://subscriptions/4be8a069-9dad-4913-a634-fc7605684d95/resourceGroups/financerag-rgf846e66535fa4a64bd/workspaces/financerag-mlwf846e66535fa4a64bd/datastores/workspaceblobstore/paths/LocalUpload/daa5911a57ed0d010cee560f2390f8e32a92db9120933793032b6d4a1f80f337/gte-finance-model', 'datastore': None, 'utc_time_created': None, 'flavors': None, 'arm_type': 'model_version', 'type': 'custom_model', 'stage': 'Development'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1753026240155
        },
        "id": "075b27a0-36e3-45a1-b46e-82226b68d0c2"
      },
      "id": "075b27a0-36e3-45a1-b46e-82226b68d0c2"
    },
    {
      "cell_type": "code",
      "source": [
        "# Command if model already registered\n",
        "# model = ml_client.models.get(name=\"gte-finance-model\",version=1)"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "id": "L61-QrGXeM4L"
      },
      "id": "L61-QrGXeM4L"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create enviornment from base Image"
      ],
      "metadata": {
        "id": "HKpSfkKTQa6a"
      },
      "id": "HKpSfkKTQa6a"
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model/environment.yml\n",
        "name: embedding_inference_env\n",
        "channels:\n",
        "  - conda-forge\n",
        "  - pytorch\n",
        "  - defaults\n",
        "dependencies:\n",
        "  - python=3.10\n",
        "  - pip=23.1.2\n",
        "  - pip:\n",
        "    - sentence-transformers>=2.2.2\n",
        "    - torch>=2.0.0\n",
        "    - transformers>=4.30.0\n",
        "    - peft>=0.4.0\n",
        "    - numpy>=1.24.0\n",
        "    - tqdm>=4.65.0\n",
        "    - scikit-learn>=1.2.2\n",
        "    - joblib\n",
        "    - azureml-inference-server-http\n",
        "    - inference-schema"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing model/environment.yml\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "id": "yBzVPaoIUAyd",
        "gather": {
          "logged": 1753026319940
        }
      },
      "id": "yBzVPaoIUAyd"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create environment\n",
        "environment = Environment(\n",
        "    name=\"gte-finance-env\",\n",
        "    description=\"Environment for GTE Finance model\",\n",
        "    conda_file=\"model/environment.yml\",\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1753026363640
        },
        "id": "fe5f031c-dc5b-451e-86fe-3d2cfc004e01",
        "outputId": "df18ae94-43e2-40b0-c0cf-944a9ef51817"
      },
      "id": "fe5f031c-dc5b-451e-86fe-3d2cfc004e01"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Endpoint"
      ],
      "metadata": {
        "id": "zhfc44Z3Qj1J"
      },
      "id": "zhfc44Z3Qj1J"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a deployment\n",
        "\n",
        "# Create or update the endpoint\n",
        "ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
        "print(f\"Endpoint '{endpoint_name}' created or updated successfully\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Endpoint 'gte-finance-endpoint' created or updated successfully\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1753029431199
        },
        "id": "09d3af7f-2fe3-4192-8778-9afdf3508b42",
        "outputId": "22d994d4-76f6-4283-d092-adda23269c54"
      },
      "id": "09d3af7f-2fe3-4192-8778-9afdf3508b42"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Score.py file for Model Inference"
      ],
      "metadata": {
        "id": "Uz-ySwBWXgc9"
      },
      "id": "Uz-ySwBWXgc9"
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model/score.py\n",
        "import os\n",
        "import json\n",
        "import logging\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Declare globals at the module level\n",
        "model = None\n",
        "config = {}\n",
        "\n",
        "def init():\n",
        "    \"\"\"\n",
        "    Initialize the model when the container starts.\n",
        "    This function is called once when the service is deployed.\n",
        "    \"\"\"\n",
        "    global model, config\n",
        "\n",
        "    logging.info(\"Initializing GTE Finance model\")\n",
        "\n",
        "    # Centralized configuration\n",
        "    config = {\n",
        "        \"embedding_batch_size\": 16,\n",
        "        \"show_progress_bar\": False,\n",
        "        \"normalize_embeddings\": False,\n",
        "        \"max_seq_length\": 2000\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Get base path from environment variable\n",
        "        base_model_dir = os.getenv(\"AZUREML_MODEL_DIR\", \"\")\n",
        "\n",
        "        # If the environment variable is not set, use fallback path\n",
        "        if not base_model_dir:\n",
        "            base_model_dir = \"/var/azureml-app/azureml-models/gte-finance-model/1\"\n",
        "\n",
        "        # Recursive function to find potential model directories\n",
        "        def find_model_dirs(directory, max_depth=5, current_depth=0):\n",
        "            if current_depth > max_depth or not os.path.exists(directory):\n",
        "                return []\n",
        "\n",
        "            potential_dirs = []\n",
        "\n",
        "            # Check if this directory could be a model directory\n",
        "            if any(os.path.exists(os.path.join(directory, f)) for f in\n",
        "                  [\"config.json\", \"config_sentence_transformers.json\", \"modules.json\"]):\n",
        "                potential_dirs.append(directory)\n",
        "\n",
        "            # Recursively check subdirectories\n",
        "            try:\n",
        "                for item in os.listdir(directory):\n",
        "                    item_path = os.path.join(directory, item)\n",
        "                    if os.path.isdir(item_path):\n",
        "                        potential_dirs.extend(find_model_dirs(item_path, max_depth, current_depth + 1))\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "            return potential_dirs\n",
        "\n",
        "        # Find all potential model directories\n",
        "        potential_model_dirs = find_model_dirs(base_model_dir)\n",
        "\n",
        "        # Try loading the model from each potential directory\n",
        "        model = None\n",
        "\n",
        "        # Try loading from Hugging Face hub as a fallback option\n",
        "        try:\n",
        "            model = SentenceTransformer(\"Yaksh170802/gte-finance-model\",trust_remote_code=True)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        # If Hugging Face loading failed, try local directories\n",
        "        if model is None:\n",
        "            for model_dir in potential_model_dirs:\n",
        "                try:\n",
        "                    model = SentenceTransformer(model_dir)\n",
        "                    break\n",
        "                except Exception:\n",
        "                    continue\n",
        "\n",
        "        # Final attempt - try loading directly from base directory with trust_remote_code\n",
        "        if model is None:\n",
        "            model = SentenceTransformer(base_model_dir, trust_remote_code=True)\n",
        "\n",
        "        # Set max_seq_length after initialization\n",
        "        if config.get(\"max_seq_length\"):\n",
        "            model.max_seq_length = config.get(\"max_seq_length\")\n",
        "\n",
        "        logging.info(f\"Model max sequence length: {model.max_seq_length}\")\n",
        "        logging.info(\"Model loaded successfully ✅\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in model initialization: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def generate_embeddings(texts, model_instance, model_config):\n",
        "    \"\"\"\n",
        "    Generate embeddings for a list of input texts.\n",
        "\n",
        "    Args:\n",
        "        texts (list of str): The texts to embed.\n",
        "        model_instance (SentenceTransformer): The loaded model instance.\n",
        "        model_config (dict): A dictionary containing configuration for encoding.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The generated embeddings.\n",
        "    \"\"\"\n",
        "    if not model_instance:\n",
        "        raise RuntimeError(\"Model has not been initialized. Call init() first.\")\n",
        "\n",
        "    # Generate embeddings\n",
        "    embeddings = model_instance.encode(\n",
        "        texts,\n",
        "        batch_size=model_config.get(\"embedding_batch_size\", 16),\n",
        "        show_progress_bar=model_config.get(\"show_progress_bar\", False),\n",
        "        normalize_embeddings=model_config.get(\"normalize_embeddings\", False)\n",
        "    )\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "def run(raw_data):\n",
        "    \"\"\"\n",
        "    Run a prediction on the input data.\n",
        "    This function is called for each scoring request.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        logging.info(\"Received input data for scoring\")\n",
        "        data = json.loads(raw_data)\n",
        "\n",
        "        texts = data.get(\"texts\", [])\n",
        "        if not isinstance(texts, list) or not texts:\n",
        "            return json.dumps({\n",
        "                \"error\": \"Input must be a JSON object with a 'texts' key containing a non-empty list of strings.\"\n",
        "            })\n",
        "\n",
        "        # Generate embeddings using the loaded model and config\n",
        "        embeddings = generate_embeddings(texts, model, config)\n",
        "\n",
        "        # Prepare the successful response\n",
        "        response = {\n",
        "            \"embeddings\": embeddings.tolist(),\n",
        "            \"dimensions\": embeddings.shape[1],\n",
        "            \"count\": len(texts)\n",
        "        }\n",
        "\n",
        "        return json.dumps(response)\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        logging.error(\"Failed to decode JSON from input data.\")\n",
        "        return json.dumps({\"error\": \"Invalid JSON format received.\"})\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error during prediction: {str(e)}\", exc_info=True)\n",
        "        return json.dumps({\"error\": str(e)})"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting model/score.py\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "id": "AmRpz_EhTlR_"
      },
      "id": "AmRpz_EhTlR_"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "aN6ydZf5G4mr"
      },
      "id": "aN6ydZf5G4mr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize Managed Endpoint Deployment"
      ],
      "metadata": {
        "id": "xfd4wiCfQxNm"
      },
      "id": "xfd4wiCfQxNm"
    },
    {
      "cell_type": "code",
      "source": [
        "deployment_name =  \"gte-finance-deployment\"\n",
        "instance_type = \"Standard_E4s_v3\"\n",
        "deployment = ManagedOnlineDeployment(\n",
        "    name=deployment_name,\n",
        "    endpoint_name=endpoint_name,\n",
        "    model=model.id,\n",
        "    environment=environment,\n",
        "    code_configuration=CodeConfiguration(\n",
        "        code=\"./model\",\n",
        "        scoring_script=\"score.py\"  # This must match the name of your script in the src directory\n",
        "    ),\n",
        "    instance_type=instance_type,\n",
        "    instance_count=2,\n",
        "    environment_variables={\n",
        "        \"MAX_SEQUENCE_LENGTH\": \"2000\",\n",
        "        \"SENTENCE_TRANSFORMERS_HOME\": \"/var/azureml-app/sentence_transformers_cache\"\n",
        "    },\n",
        "    request_settings = OnlineRequestSettings(request_timeout_ms = 180000)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1753046698191
        },
        "id": "e20b4290-8f71-47fd-8c5d-9a8263e37da0"
      },
      "id": "e20b4290-8f71-47fd-8c5d-9a8263e37da0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Deployment"
      ],
      "metadata": {
        "id": "a27t0r7SQ57v"
      },
      "id": "a27t0r7SQ57v"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create or update the deployment\n",
        "ml_client.online_deployments.begin_create_or_update(deployment).result()\n",
        "print(f\"Deployment '{deployment_name}' created or updated successfully\")\n",
        "\n",
        "# Allocate traffic to the deployment\n",
        "endpoint = ml_client.online_endpoints.get(name=endpoint_name)\n",
        "\n",
        "# Update traffic\n",
        "ml_client.online_endpoints.begin_create_or_update(\n",
        "    ManagedOnlineEndpoint(\n",
        "        name=endpoint_name,\n",
        "        traffic={deployment_name: 100}\n",
        "    )\n",
        ").result()\n",
        "\n",
        "print(f\"Traffic allocated to deployment '{deployment_name}'\")\n",
        "print(f\"Endpoint URL: {endpoint.scoring_uri}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Check: endpoint gte-finance-endpoint exists\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        }
      ],
      "execution_count": 35,
      "metadata": {
        "gather": {
          "logged": 1753046682260
        }
      },
      "id": "c5324608-a2a2-452d-996e-61f532a0fad1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Deployment"
      ],
      "metadata": {
        "id": "AcKgyf1CQ9Cw"
      },
      "id": "AcKgyf1CQ9Cw"
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = \"\"\"Germany,[d] officially the Federal Republic of Germany,[e] is a country in Central Europe. It lies between the Baltic Sea and the North Sea to the north and the Alps to the south. Its sixteen constituent states have a total population of over 82 million in an area of 357,596 km2 (138,069 sq mi), making it the most populous member state of the European Union. Germany borders Denmark to the north, Poland and the Czech Republic to the east, Austria and Switzerland to the south, and France, Luxembourg, Belgium, and the Netherlands to the west. The nation's capital and most populous city is Berlin and its main financial centre is Frankfurt; the largest urban area is the Ruhr.\n",
        "\n",
        "Settlement in the territory of modern Germany began in the Lower Paleolithic, with various tribes inhabiting it from the Neolithic onward, chiefly the Celts. Various Germanic tribes have inhabited the northern parts of modern Germany since classical antiquity. A region named Germania was documented before AD 100. In 962, the Kingdom of Germany formed the bulk of the Holy Roman Empire. During the 16th century, northern German regions became the centre of the Protestant Reformation. Following the Napoleonic Wars and the dissolution of the Holy Roman Empire in 1806, the German Confederation was formed in 1815.\n",
        "\n",
        "Formal unification of Germany into the modern nation-state commenced on 18 August 1866 with the North German Confederation Treaty establishing the Prussia-led North German Confederation, which became the German Empire in 1871. After World War I and the German Revolution of 1918–1919, the Empire was replaced by the Weimar Republic. The Nazi rise to power in 1933 led to the establishment of a totalitarian dictatorship, World War II, and the Holocaust. In 1949, after the war and a period of Allied occupation, Germany was organised into two separate polities with limited sovereignty: the Federal Republic of Germany, or West Germany, and the German Democratic Republic, or East Germany. Berlin continued its de jure Four Power status. The Federal Republic of Germany was a founding member of the Council of Europe, the European Economic Community and the European Union in 1951, while the German Democratic Republic was a communist Eastern Bloc state and member of the Warsaw Pact. After the fall of the communist led-government in East Germany, German reunification saw the former East German states join the Federal Republic of Germany on 3 October 1990.\n",
        "\n",
        "Germany is a developed country with a strong economy; it has the largest economy in Europe by nominal GDP. As a major force in several industrial, scientific and technological sectors, Germany is both the world's third-largest exporter and third-largest importer. It offers social security, a universal health care system, and tuition-free university education. Widely considered a great power, Germany is part of multiple international organisations and forums. It has the third-highest number of UNESCO World Heritage Sites: 55, of which 52 are cultural.\n",
        "\n",
        "Etymology\n",
        "Further information: Names of Germany, Germani, and Germania\n",
        "The English word Germany derives from the Latin Germania, which came into use after Julius Caesar adopted it for the peoples east of the Rhine.[12] The German term Deutschland, originally diutisciu land ('the German lands'), is derived from deutsch (cf. Dutch), which descended from Old High German diutisc 'of the people' (from diot or diota 'people'), originally used to distinguish the language of the common people from Latin and its Romance descendants. This in turn descends from Proto-Germanic *þiudiskaz 'of the people' (see also the Latinised form Theodiscus), derived from *þeudō, descended from Proto-Indo-European *tewtéh₂- 'people', from which the word Teutons also originates.[13]\n",
        "\n",
        "History\"\"\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "77985bf7-27e3-4a23-b00d-e3d0be1bd2a8"
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import json\n",
        "\n",
        "# Request data goes here\n",
        "# The example below assumes JSON formatting which may be updated\n",
        "# depending on the format your endpoint expects.\n",
        "# More information can be found here:\n",
        "# https://docs.microsoft.com/azure/machine-learning/how-to-deploy-advanced-entry-script\n",
        "data = {\"texts\":[corpus for i in range(32)]}\n",
        "\n",
        "body = str.encode(json.dumps(data))\n",
        "\n",
        "url = 'https://gte-finance-endpoint.eastus.inference.ml.azure.com/score'\n",
        "# Replace this with the primary/secondary key, AMLToken, or Microsoft Entra ID token for the endpoint\n",
        "api_key = ''\n",
        "if not api_key:\n",
        "    raise Exception(\"A key should be provided to invoke the endpoint\")\n",
        "\n",
        "\n",
        "headers = {'Content-Type':'application/json', 'Accept': 'application/json', 'Authorization':('Bearer '+ api_key)}\n",
        "\n",
        "req = urllib.request.Request(url, body, headers)\n",
        "\n",
        "try:\n",
        "    response = urllib.request.urlopen(req)\n",
        "\n",
        "    result = response.read()\n",
        "    result = json.loads(json.loads(result.decode('utf-8')))\n",
        "\n",
        "    print(result)\n",
        "except urllib.error.HTTPError as error:\n",
        "    print(\"The request failed with status code: \" + str(error.code))\n",
        "\n",
        "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
        "    print(error.info())\n",
        "    print(error.read().decode(\"utf8\", 'ignore'))\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "8dddf0f0-e713-4c17-ba9d-31b57d0a717f"
      },
      "id": "8dddf0f0-e713-4c17-ba9d-31b57d0a717f"
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.10 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}